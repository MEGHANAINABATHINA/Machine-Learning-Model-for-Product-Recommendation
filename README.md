# Machine-Learning-Model-for-Product-Recommendation
"""skincare products.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9trbaJrkecP8JzFn0uYO8YEhA4dpm-a
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score

data=pd.read_csv('/content/skincare.csv')

data.head()

data.info()

data.describe()

## Get unique values for each column without any modification
unique_title_names=data['Title'].unique().tolist()
unique_product_names = data['Product'].unique().tolist()
unique_brand_names = data['Brand'].unique().tolist()
unique_skin_type_names = data['Skin_Type'].unique().tolist()
unique_sold_by_names = data['Sold By'].unique().tolist()

# Display the lists of unique values
print("\nUnique Title Names:")
print(unique_title_names)

print("Unique Product Names:")
print(unique_product_names)

print("\nUnique Brand Names:")
print(unique_brand_names)

print("\nUnique Skin Types:")
print(unique_skin_type_names)

print("\nUnique Sold By Names:")
print(unique_sold_by_names)

data['Brand'] = data['Brand'].fillna(data['Brand'].mode()[0])
data['Skin_Type'] = data['Skin_Type'].fillna(data['Skin_Type'].mode()[0])
data['Price'] = data['Price'].fillna(data['Price'].median())

# Check for missing values in the entire dataset
missing_values = data.isnull().sum()

# Display the columns with missing values
print("Missing Values in Each Column:")
print(missing_values)

# Fill missing values
# For numeric columns, fill with the median (or any strategy you prefer)
data['Price'] = data['Price'].fillna(data['Price'].median())
# For categorical columns, fill with the most frequent value (mode)
data['Brand'] = data['Brand'].fillna(data['Brand'].mode()[0])
data['Skin_Type'] = data['Skin_Type'].fillna(data['Skin_Type'].mode()[0])
data['Sold By'] = data['Sold By'].fillna(data['Sold By'].mode()[0])

# Check again for missing values after filling
missing_values_after_filling = data.isnull().sum()

# Display missing values after filling
print("\nMissing Values After Filling:")
print(missing_values_after_filling)

# Drop duplicate entries
data.drop_duplicates(inplace=True)

# Verify duplicates are removed
print("Number of duplicates:", data.duplicated().sum())

# Ensure 'Price' is numeric
data['Price'] = data['Price'].astype(float)

# Optionally scale the 'Price' column (if necessary)
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()  # Scale Price to a range of 0 to 1
data['Scaled_Price'] = scaler.fit_transform(data[['Price']])

# Use 'Scaled_Price' for regression if needed

# Encoding categorical features (Product, Brand, Skin_Type)
product_encoder = LabelEncoder()
data['Product'] = product_encoder.fit_transform(data['Product'])

brand_encoder = LabelEncoder()
data['Brand'] = brand_encoder.fit_transform(data['Brand'])

skin_type_encoder = LabelEncoder()
data['Skin_Type'] = skin_type_encoder.fit_transform(data['Skin_Type'])

# Prepare features and labels for training
X = data[['Product', 'Brand', 'Skin_Type']].values
# Selecting multiple columns using a list of column names
y = data[['Product', 'Brand', 'Skin_Type','Price']].values  # Target variable can be Price or Ratings

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training Set Size: {X_train.shape[0]}")
print(f"Testing Set Size: {X_test.shape[0]}")

from sklearn.preprocessing import OneHotEncoder

# One-Hot encode the categorical target variables (Product, Brand, Skin_Type)
# One-Hot encode the categorical target variables (Product, Brand, Skin_Type)
encoder_product = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoder_brand = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoder_skin_type = OneHotEncoder(sparse_output=False, handle_unknown='ignore')# Change 'sparse' to 'sparse_output'

y_product = encoder_product.fit_transform(y_train[:, 0].reshape(-1, 1))
y_brand = encoder_brand.fit_transform(y_train[:, 1].reshape(-1, 1))
y_skin_type = encoder_skin_type.fit_transform(y_train[:, 2].reshape(-1, 1))

# Reshape the price column to have 2 dimensions
y_price = y_train[:, 3].reshape(-1, 1)

# Combine the encoded variables into a single target array
y_train_encoded = np.hstack([y_product, y_brand, y_skin_type, y_price])

# Similarly, for the test set:
y_product_test = encoder_product.transform(y_test[:, 0].reshape(-1, 1))
y_brand_test = encoder_brand.transform(y_test[:, 1].reshape(-1, 1))
y_skin_type_test = encoder_skin_type.transform(y_test[:, 2].reshape(-1, 1))

# Reshape the price column for the test set
y_price_test = y_test[:, 3].reshape(-1, 1)

# Combine the encoded variables into a single test target array
y_test_encoded = np.hstack([y_product_test, y_brand_test, y_skin_type_test, y_price_test])

print(f"Encoded y_train shape: {y_train_encoded.shape}")
print(f"Encoded y_test shape: {y_test_encoded.shape}")

# Function to build the multi-output recommendation model
def build_model(num_products, num_brands, num_skin_types, embedding_dim=50):
    product_input = tf.keras.Input(shape=(1,), name='Product_Input')
    brand_input = tf.keras.Input(shape=(1,), name='Brand_Input')
    skin_type_input = tf.keras.Input(shape=(1,), name='Skin_Type_Input')

    # Embedding layers for each input feature
    product_embedding = tf.keras.layers.Embedding(num_products, embedding_dim)(product_input)
    brand_embedding = tf.keras.layers.Embedding(num_brands, embedding_dim)(brand_input)
    skin_type_embedding = tf.keras.layers.Embedding(num_skin_types, embedding_dim)(skin_type_input)

    # Flatten the embedding layers
    product_flat = tf.keras.layers.Flatten()(product_embedding)
    brand_flat = tf.keras.layers.Flatten()(brand_embedding)
    skin_type_flat = tf.keras.layers.Flatten()(skin_type_embedding)

    # Concatenate the embeddings
    concatenated = tf.keras.layers.concatenate([product_flat, brand_flat, skin_type_flat])

    # Dense layers for final prediction
    dense = tf.keras.layers.Dense(128, activation='relu')(concatenated)

    # Multiple outputs: Product, Brand, Skin_Type, and Price
    product_output = tf.keras.layers.Dense(1, activation='linear', name='Product_Output')(dense)
    brand_output = tf.keras.layers.Dense(1, activation='linear', name='Brand_Output')(dense)
    skin_type_output = tf.keras.layers.Dense(1, activation='linear', name='Skin_Type_Output')(dense)
    price_output = tf.keras.layers.Dense(1, activation='linear', name='Price_Output')(dense)

    # Corrected line: Removed the undefined variable 't'
    model = tf.keras.Model(inputs=[product_input, brand_input, skin_type_input], outputs=[product_output, brand_output, skin_type_output, price_output])
    model.compile(optimizer='adam',
                  loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy', 'mse'],
                  # Provide a metric for each output
                  metrics=[['accuracy'], ['accuracy'], ['accuracy'], ['mae', 'mse']])
    return model

# Get the number of unique values for each feature
num_products = len(data['Product'].unique())
num_brands = len(data['Brand'].unique())
num_skin_types = len(data['Skin_Type'].unique())

# Build and summarize the model
model = build_model(num_products, num_brands, num_skin_types)
model.summary()

# Train the model
history = model.fit(
    [X_train[:, 0], X_train[:, 1], X_train[:, 2]],  # Input: Product, Brand, Skin_Type
    [y_train[:, 0], y_train[:, 1], y_train[:, 2], y_train[:, 3]],  # Targets: Product, Brand, Skin_Type, Price
    epochs=10,
    batch_size=32,
    validation_data=([X_test[:, 0], X_test[:, 1], X_test[:, 2]], [y_test[:, 0], y_test[:, 1], y_test[:, 2], y_test[:, 3]])
)

# Evaluate the model on the test set
evaluation = model.evaluate(
    [X_test[:, 0], X_test[:, 1], X_test[:, 2]],  # Input features
    [y_test[:, 0], y_test[:, 1], y_test[:, 2], y_test[:, 3]]  # Targets: Product, Brand, Skin_Type, Price
)

# Print results for each output
print("Evaluation Results:")
for i, output_name in enumerate(model.output_names):
    print(f"{output_name}: Loss = {evaluation[i*2]:.4f}, Metric = {evaluation[i*2+1]:.4f}")

# Evaluate the model
evaluation = model.evaluate(
    [X_test[:, 0], X_test[:, 1], X_test[:, 2]],  # Inputs
    [y_test[:, 0], y_test[:, 1], y_test[:, 2], y_test[:, 3]]  # True values
)

print("Evaluation Results:")
print(f"Product Prediction - Accuracy: {evaluation[1]:.2f}")
print(f"Brand Prediction - Accuracy: {evaluation[3]:.2f}")
print(f"Skin Type Prediction - Accuracy: {evaluation[5]:.2f}")
print(f"Price Prediction - Mean Absolute Error: {evaluation[7]:.2f}")

# Generate predictions
predictions = model.predict([X_test[:, 0], X_test[:, 1], X_test[:, 2]])

# Extract predicted and true labels for evaluation
y_pred_product = predictions[0]
y_pred_brand = predictions[1]
y_pred_skin_type = predictions[2]
y_pred_price = predictions[3]

# Convert one-hot encoded predictions back to labels for categorical outputs
y_true_product = y_test[:, 0]
y_true_brand = y_test[:, 1]
y_true_skin_type = y_test[:, 2]

from sklearn.metrics import precision_score, recall_score, f1_score

# Convert predictions to labels (if applicable)
y_pred_product_labels = np.argmax(y_pred_product, axis=1)
y_pred_brand_labels = np.argmax(y_pred_brand, axis=1)
y_pred_skin_type_labels = np.argmax(y_pred_skin_type, axis=1)

# Calculate metrics for product predictions
precision = precision_score(y_true_product, y_pred_product_labels, average='weighted')
recall = recall_score(y_true_product, y_pred_product_labels, average='weighted')
f1 = f1_score(y_true_product, y_pred_product_labels, average='weighted')

print(f"Precision (Product): {precision:.2f}")
print(f"Recall (Product): {recall:.2f}")
print(f"F1-Score (Product): {f1:.2f}")

product_counts = pd.Series(y_train[:, 0]).value_counts()
print("Class distribution for products:\n", product_counts)

model = build_model(num_products, num_brands, num_skin_types, embedding_dim=100)

model.compile(
    optimizer='adam',
    loss={
        'Product_Output': 'categorical_crossentropy',
        'Brand_Output': 'categorical_crossentropy',
        'Skin_Type_Output': 'categorical_crossentropy',
        'Price_Output': 'mse'
    },
    loss_weights={
        'Product_Output': 2.0,  # Emphasize product prediction
        'Brand_Output': 1.0,
        'Skin_Type_Output': 1.0,
        'Price_Output': 0.5
    },
    metrics=['accuracy']
)

from sklearn.metrics import classification_report

print("Product Classification Report:")
print(classification_report(y_true_product, y_pred_product_labels, zero_division=0))

# Get predictions
predictions = model.predict([X_test[:, 0], X_test[:, 1], X_test[:, 2]])

# Convert one-hot predictions back to class labels
y_pred_product_labels = np.argmax(predictions[0], axis=1)
y_pred_brand_labels = np.argmax(predictions[1], axis=1)
y_pred_skin_type_labels = np.argmax(predictions[2], axis=1)

# Count correct predictions
correct_predictions = (
    (y_test[:, 0] == y_pred_product_labels) &
    (y_test[:, 1] == y_pred_brand_labels) &
    (y_test[:, 2] == y_pred_skin_type_labels)
).sum()

# Calculate overall accuracy
overall_accuracy = correct_predictions / len(y_test)
print(f"Overall Accuracy: {overall_accuracy:.2f}")

from sklearn.metrics import mean_absolute_error

y_pred_price = predictions[3].flatten()
price_mae = mean_absolute_error(y_test[:, 3], y_pred_price)

print(f"Price Prediction Mean Absolute Error (MAE): {price_mae:.2f}")

import matplotlib.pyplot as plt

# Plot accuracy
plt.plot(history.history['Product_Output_accuracy'], label='Product Accuracy')
plt.plot(history.history['Brand_Output_accuracy'], label='Brand Accuracy')
plt.plot(history.history['Skin_Type_Output_accuracy'], label='Skin Type Accuracy')
plt.legend()
plt.title('Model Accuracy')
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Total Loss')
plt.legend()
plt.title('Model Loss')
plt.show()

plt.plot(history.history['Product_Output_accuracy'], label='Train Accuracy')
plt.plot(history.history['val_Product_Output_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

# Visualize the evaluation metrics
metrics = pd.DataFrame({
    'Metric': ['Precision', 'Recall', 'F1-Score'],
    'Score': [precision, recall, f1]
})

plt.figure(figsize=(8, 5))
sns.barplot(x='Metric', y='Score', data=metrics, palette='Blues_d')
plt.title('Model Evaluation Metrics')
plt.show()
